---
layout:     post
title:      Youtube2019双塔召回论文精读
subtitle:   youtube论文精读
date:       2017-06-19
author:     BY
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - youtube
    - 召回
    - 双塔
---

今年Recsys上youtube出了两篇论文，虽然youtube中国推荐做的贼烂，但是论文依旧延续了精品的传统。

yougth这里对其中热度不是那么高的一篇《Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations》做一个精读。

### 总体思路

首先大体来讲，一个很有意思的点是，google也开始采用双塔召回了。至少从目前发的论文来看，没有在之前16年发布的论文NN结构基础上探索，那篇文章在之前的文章[youtube深度学习推荐经典论文中关键点](http://yougth.top/2019/09/11/youtube%E6%8E%A8%E8%8D%90%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%85%B3%E9%94%AE%E7%82%B9/)中分析过，而是采用了现在主流的双塔模型，双塔模型是在2013年微软发布的DSSM模型上发展来的，当初提出是为了文章检索设计的，双塔分别对应query和doc。现在推荐主流上用双塔都是user embedding塔和item embedding塔，总体结构如下图。

![整体思路](http://yougth.top/img/youtube/2019-10-1.png)

基本上结构很清晰，首先按照结构训练模型，模型训练好用图中的两个向量u(x)和v(y)求dot，对相似度高的item做推荐。其中两部分，左侧user塔后面的user embedding需要在请求来的时候实时计算，右侧item塔训练的时候预计算好，然后灌入一个向量检索工具中，首先建立索引，然后转化为一个向量检索问题，这方面基本做推荐的各家大公司都有自己的开源工具，比如faiss，annoy等。

### 模型结构

这里我们用x表示user和context特征，y表示item特征，$$\theta$$表示模型中的参数，则结果可以这样表示。

$$
sim(x,y) = <u(x,\theta), v(y,\theta)>
$$

假设有T条训练样本，模型的目标是从这些训练样本中学习模型参数$$\theta$$。每一条训练样本定义为

$$
\tau := {(x_i, y_i, r_i)}_{i=1}^T
$$

其中$$x_i$$表示用户特征和上下文特征，$$y_i$$表示物品特征，$$r_i$$表示每对样本的回报，比如文章的阅读时常，视频的播放比例等。那么这个问题可以认为是一个多分类问题，给一个用户x，从M个items的候选集$${y_j}_{j=1}^M$$中选择要推荐的item。多分类softmax函数定义为

$$
\rho (y|x; \theta) = \frac{e^{s(x,y)}}{\sum_{j \in [M]} e^{s(x,y_j)}}
$$

定义对数似然函数

$$
L_T(\theta) := -\frac{1}{T} \sum_{i \in [T]} r_i \dot log(\rho(y_i|x_i; \theta))
$$

### 网络结构

![详细结构](http://yougth.top/img/youtube/2019-10-2.jpg)
